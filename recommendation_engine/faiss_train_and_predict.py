import pandas as pd
import numpy as np
import faiss
import json
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler

class SettlementRecommendationEngine:
    def __init__(self, csv_path='transactions.csv'):
        self.df = pd.read_csv(csv_path)
        self.vectorizer = TfidfVectorizer(max_features=100)
        self.scaler = StandardScaler()
        self.index = None
        self.feature_matrix = None
        
    def preprocess_data(self):
        """ê±°ë˜ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        # ì‹œê°„ëŒ€ ì¶”ì¶œ (19ì‹œ -> 19)
        self.df['hour'] = pd.to_datetime(self.df['datetime']).dt.hour
        
        # ì¥ì†Œëª… ë²¡í„°í™”
        place_features = self.vectorizer.fit_transform(self.df['place']).toarray()
        
        # ìˆ˜ì¹˜ íŠ¹ì„± ì •ê·œí™” (ì‹œê°„, ê¸ˆì•¡)
        numeric_features = self.scaler.fit_transform(self.df[['hour', 'amount']])
        
        # ëª¨ë“  íŠ¹ì„± ê²°í•©
        self.feature_matrix = np.hstack([place_features, numeric_features])
        
        print(f"Feature matrix shape: {self.feature_matrix.shape}")
        return self.feature_matrix
    
    def build_faiss_index(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        features = self.preprocess_data()
        dimension = features.shape[1]
        
        # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(features.astype('float32'))
        
        print(f"FAISS index built with {self.index.ntotal} vectors")
        
    def get_recommendations(self, place, hour, amount, k=3):
        """ìœ ì‚¬í•œ ê±°ë˜ ì°¾ì•„ì„œ ì°¸ì—¬ì ì¶”ì²œ"""
        if self.index is None:
            self.build_faiss_index()
        
        # ì¿¼ë¦¬ ë²¡í„° ìƒì„±
        query_place = self.vectorizer.transform([place]).toarray()
        query_numeric = self.scaler.transform([[hour, amount]])
        query_vector = np.hstack([query_place, query_numeric]).astype('float32')
        
        # ìœ ì‚¬í•œ ê±°ë˜ ê²€ìƒ‰
        distances, indices = self.index.search(query_vector, k)
        
        # ì¶”ì²œ ê²°ê³¼ ìƒì„±
        recommendations = []
        participant_counts = {}
        
        for i, idx in enumerate(indices[0]):
            if distances[0][i] < float('inf'):  # ìœ íš¨í•œ ê²°ê³¼ë§Œ
                row = self.df.iloc[idx]
                participants = row['participants'].split('|')
                similarity_score = 1 / (1 + distances[0][i])  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                
                recommendations.append({
                    'place': row['place'],
                    'datetime': row['datetime'],
                    'amount': int(row['amount']),
                    'participants': participants,
                    'similarity': float(similarity_score),
                    'distance': float(distances[0][i])
                })
                
                # ì°¸ì—¬ìë³„ ë¹ˆë„ ê³„ì‚°
                for participant in participants:
                    participant_counts[participant] = participant_counts.get(participant, 0) + similarity_score
        
        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì°¸ì—¬ìë“¤ ì„ ë³„
        top_participants = sorted(participant_counts.items(), key=lambda x: x[1], reverse=True)[:4]
        
        return {
            'recommended_participants': [p[0] for p in top_participants],
            'confidence_scores': {p[0]: float(p[1]) for p in top_participants},
            'similar_transactions': recommendations,
            'explanation': f"ê³¼ê±° '{recommendations[0]['place']}' ì •ì‚° ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤." if recommendations else "ìœ ì‚¬í•œ ì •ì‚° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        }

def generate_recommendations_json():
    """ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì¶”ì²œ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ìƒì„±"""
    engine = SettlementRecommendationEngine()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    test_scenarios = [
        {'place': 'í‰ì´Œìª½ê°ˆë¹„', 'hour': 19, 'amount': 70000},
        {'place': 'ë§¥ë„ë‚ ë“œ í‰ì´Œì ', 'hour': 20, 'amount': 30000},
        {'place': 'ìŠ¤íƒ€ë²…ìŠ¤ ë²”ê³„ì ', 'hour': 18, 'amount': 15000},
        {'place': 'êµì´Œì¹˜í‚¨ í‰ì´Œì ', 'hour': 19, 'amount': 40000},
        {'place': 'ê¹€ë°¥ì²œêµ­', 'hour': 19, 'amount': 20000},
    ]
    
    recommendations = {}
    
    for scenario in test_scenarios:
        key = f"{scenario['place']}_{scenario['hour']}_{scenario['amount']}"
        result = engine.get_recommendations(
            scenario['place'], 
            scenario['hour'], 
            scenario['amount']
        )
        recommendations[key] = result
        
        print(f"\n--- {scenario['place']} ì¶”ì²œ ê²°ê³¼ ---")
        print(f"ì¶”ì²œ ì°¸ì—¬ì: {result['recommended_participants']}")
        print(f"ì„¤ëª…: {result['explanation']}")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('recommendations.json', 'w', encoding='utf-8') as f:
        json.dump(recommendations, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… recommendations.json íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    return recommendations

if __name__ == "__main__":
    print("ğŸ¤– FAISS ê¸°ë°˜ ì •ì‚° ì°¸ì—¬ì ì¶”ì²œ ì—”ì§„ ì‹œì‘...")
    results = generate_recommendations_json()
    print(f"âœ… {len(results)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì¶”ì²œ ì™„ë£Œ!")
